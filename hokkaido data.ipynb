{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from geopy.geocoders import MapBox\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get city / prefecture geographic corrdinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Downloads/od_data_hokkaido/od_data_hokkaido.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arr'] = df['Destination Prefecture']+df['Destination City']\n",
    "df['dep'] = df['Origin Prefecture']+df['Origin City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_cityname = pd.concat([df['arr'], df['dep']]\n",
    "                       ).drop_duplicates().reset_index(drop=True)\n",
    "df_cityname = pd.DataFrame({'cityname': s_cityname})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = MapBox(\n",
    "    api_key='pk.eyJ1Ijoic3RpbGxiZW5nYmVuZyIsImEiOiJja2M1eHBpa2Qwamh2MnBxczhlcjlnazV0In0.hVW33t9_bUQ0lrtDOBl7aw')\n",
    "for i in range(len(s_cityname)):\n",
    "    if geolocator.geocode(s_cityname[i]) is None:\n",
    "        print(s_cityname[i])\n",
    "    else:\n",
    "        df_cityname.loc[i, 'lat'] = geolocator.geocode(\n",
    "            s_cityname[i], timeout=10).latitude\n",
    "        df_cityname.loc[i, 'lon'] = geolocator.geocode(\n",
    "            s_cityname[i], timeout=10).longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_prefecturename = df['Origin Prefecture'].drop_duplicates(\n",
    ").reset_index(drop=True)\n",
    "df_prefecturename = pd.DataFrame({'prefecturename': s_prefecturename})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = MapBox(\n",
    "    api_key='pk.eyJ1Ijoic3RpbGxiZW5nYmVuZyIsImEiOiJja2M1eHBpa2Qwamh2MnBxczhlcjlnazV0In0.hVW33t9_bUQ0lrtDOBl7aw')\n",
    "for i in range(len(s_prefecturename)):\n",
    "    if geolocator.geocode(s_cityname[i]) is None:\n",
    "        print(s_cityname[i])\n",
    "    else:\n",
    "        df_prefecturename.loc[i, 'lat'] = geolocator.geocode(\n",
    "            s_prefecturename[i], timeout=10).latitude\n",
    "        df_prefecturename.loc[i, 'lon'] = geolocator.geocode(\n",
    "            s_prefecturename[i], timeout=10).longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cityname = pd.read_csv('../Documents/ipynb/Hokkaido_cityname.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prefecturename = pd.read_csv(\n",
    "    '../DDD_locationmind/Hokkaido_prefecturename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_drop = df[~(df['arr'] == df['dep'])]\n",
    "df_drop = df_drop.drop(['Arrcity', 'Depcity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_drop['Date'] = df_drop['Date'].apply(\n",
    "    lambda x: datetime.strptime(x, '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df_drop['time'] = df_drop['Date'].apply(lambda x: (\n",
    "    x+datetime.timedelta(hours=1)).strftime('%m/%d/%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df_drop['date'] = df_drop['Date'].apply(\n",
    "    lambda x: '{:02d}/{:02d}'.format(x.month, x.day))\n",
    "df_drop.loc['new_low', 'date'] = '02/29'\n",
    "\n",
    "df_drop['year'] = df_drop['Date'].apply(lambda x: x.year)\n",
    "df_drop['year'] = df_drop['year'].apply(lambda x: str(x))\n",
    "df_drop.loc['new_low', 'year'] = '2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_19 = df_drop.loc[df_drop['year'] == '2019', :]\n",
    "df_drop_20 = df_drop.loc[df_drop['year'] == '2020', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020 data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hkk_20 = df_drop_20[df_drop_20['Origin Prefecture'] == '北海道']\n",
    "df_nothkk_20 = df_drop_20[df_drop_20['Origin Prefecture'] != '北海道']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hkk_20_date = df_hkk_20.groupby('Date')['Ex Volume'].sum().reset_index()\n",
    "df_nothkk_20_date = df_nothkk_20.groupby(\n",
    "    'Date')['Ex Volume'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  trips between cities in Hokkaido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='hkk_20',\n",
    "           x=df_hkk_20_date['Date'], y=df_hkk_20_date['Ex Volume'])\n",
    "])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trips from outside hokkaido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='nothkk_20',\n",
    "           x=df_nothkk_20_date['Date'], y=df_nothkk_20_date['Ex Volume'])\n",
    "])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis on trips change between cities in hokkaido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## top 20 cities, descending by Destination City's volume\n",
    "list_topcity=df_hkk_20.groupby('Destination City')['Ex Volume'].sum().reset_index().sort_values('Ex Volume',ascending=False).reset_index(drop=True).iloc[:20,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data 2020.2.28 and data 2020.5.6\n",
    "\n",
    "df_hkk_20_228=df_hkk_20[df_hkk_20['Date']=='2020-02-28']\n",
    "\n",
    "df_hkk_20_506=df_hkk_20[df_hkk_20['Date']=='2020-05-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_date(data):\n",
    "    data=data[['Origin City','Destination City','Ex Volume']]\n",
    "    data_temp=data[(data['Destination City'].isin(list_topcity)) & (data['Origin City'].isin(list_topcity))]\n",
    "    data_date=data_temp.groupby(['Origin City','Destination City'])['Ex Volume'].sum().unstack().fillna(0).astype(int)\n",
    "    return data_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make heatmap figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(rows=2, cols=1,shared_yaxes=True,shared_xaxes=True,subplot_titles=('February 28, 2020','May 6, 2020'),vertical_spacing=0.1)\n",
    " \n",
    "z1=data_date(df_hkk_20_228).values\n",
    "z2=data_date(df_hkk_20_506).values\n",
    "x1=data_date(df_hkk_20_228).columns\n",
    "x2=data_date(df_hkk_20_506).columns\n",
    "y1=data_date(df_hkk_20_228).index\n",
    "y2=data_date(df_hkk_20_506).index\n",
    "\n",
    "\n",
    "fig1 = ff.create_annotated_heatmap(x=x1.tolist(), y=y1.tolist(), z=z1, hoverinfo='z',colorscale='oryel')\n",
    "fig2 = ff.create_annotated_heatmap(x=x2.tolist(), y=y2.tolist(), z=z2, hoverinfo='z',colorscale='oryel')\n",
    "\n",
    "fig.add_trace(fig1.data[0], 1, 1)\n",
    "fig.add_trace(fig2.data[0], 2, 1)\n",
    "\n",
    "for i in range(len(fig1.layout.annotations)):\n",
    "    fig1.layout.annotations[i].font.size = 8\n",
    "for i in range(len(fig2.layout.annotations)):\n",
    "    fig2.layout.annotations[i].font.size = 8\n",
    "\n",
    "annot1 = list(fig1.layout.annotations)\n",
    "annot2 = list(fig2.layout.annotations)\n",
    "   \n",
    "for k in range(len(annot2)):\n",
    "    annot2[k]['xref'] = 'x2'\n",
    "    annot2[k]['yref'] = 'y2'\n",
    "\n",
    "fig.update_layout(annotations=annot1+annot2)\n",
    "   \n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=11,\n",
    "        color=\"#555555\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(width = 1000, height = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   analysis on trips change on desitinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hkk_19 = df_drop_19[df_drop_19['Origin Prefecture'] == '北海道']\n",
    "df_nothkk_19 = df_drop_19[df_drop_19['Origin Prefecture'] != '北海道']\n",
    "\n",
    "df_hkk_20 = df_drop_20[df_drop_20['Origin Prefecture'] == '北海道']\n",
    "df_nothkk_20 = df_drop_20[df_drop_20['Origin Prefecture'] != '北海道']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vol_19_hkk = df_hkk_19['Ex Volume'].sum()\n",
    "total_vol_20_hkk = df_hkk_20['Ex Volume'].sum()\n",
    "\n",
    "total_vol_19_nothkk = df_nothkk_19['Ex Volume'].sum()\n",
    "total_vol_20_nothkk = df_nothkk_20['Ex Volume'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hkk_19.loc[:, 'rela_vol_19_hkk'] = df_hkk_19['Ex Volume']/total_vol_19_hkk\n",
    "df_nothkk_19.loc[:, 'rela_vol_19_nothkk'] = df_nothkk_19['Ex Volume'] / \\\n",
    "    total_vol_19_nothkk\n",
    "\n",
    "df_hkk_20.loc[:, 'rela_vol_20_hkk'] = df_hkk_20['Ex Volume']/total_vol_20_hkk\n",
    "df_nothkk_20.loc[:, 'rela_vol_20_nothkk'] = df_nothkk_20['Ex Volume'] / \\\n",
    "    total_vol_20_nothkk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### caculate the volume of detination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20_Dhkk = df_hkk_20.groupby('Destination City')['rela_vol_20_hkk'].sum(\n",
    ").reset_index().sort_values('rela_vol_20_hkk', ascending=False)\n",
    "\n",
    "df_20_Dnothkk = df_nothkk_20.groupby('Destination City')['rela_vol_20_nothkk'].sum(\n",
    ").reset_index().sort_values('rela_vol_20_nothkk', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19_Dhkk = df_hkk_19.groupby('Destination City')['rela_vol_19_hkk'].sum(\n",
    ").reset_index().sort_values('rela_vol_19_hkk', ascending=False)\n",
    "\n",
    "df_19_Dnothkk = df_nothkk_19.groupby('Destination City')['rela_vol_19_nothkk'].sum(\n",
    ").reset_index().sort_values('rela_vol_19_nothkk', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge_19 = pd.merge(df_19_Dhkk, df_19_Dnothkk,\n",
    "                       on='Destination City', how='outer')\n",
    "\n",
    "df_merge_20 = pd.merge(df_20_Dhkk, df_20_Dnothkk,\n",
    "                       on='Destination City', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_merge_19, df_merge_20,\n",
    "                    on='Destination City', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### difference caculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['diff_hkk'] = df_merge_20['rela_vol_20_hkk'] - \\\n",
    "    df_merge_19['rela_vol_19_hkk']\n",
    "df_merge['diff_nothkk'] = df_merge_20['rela_vol_20_nothkk'] - \\\n",
    "    df_merge_19['rela_vol_19_nothkk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge = df_merge.sort_values('diff_nothkk', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['diff_hkk'] = df_merge['diff_hkk']*100\n",
    "df_merge['diff_nothkk'] = df_merge['diff_nothkk']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make bar chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "destination_city = df_merge[:30].loc[:, 'Destination City'].tolist()\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='other prefectures', x=destination_city,\n",
    "           y=df_merge[:30].loc[:, 'diff_nothkk'].tolist(), marker_color=['#e16428']*35),\n",
    "    go.Bar(name='Hokkaido', x=destination_city,\n",
    "           y=df_merge[:30].loc[:, 'diff_hkk'].tolist(), marker_color=['#bebec0']*35)\n",
    "])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showline=True,\n",
    "        showgrid=False,\n",
    "        showticklabels=True,\n",
    "        linecolor='rgb(204, 204, 204)',\n",
    "        linewidth=2,\n",
    "        ticks='outside',\n",
    "        tickfont=dict(\n",
    "            family='Arial', size=12,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        zeroline=True,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "    ),\n",
    "    autosize=False,\n",
    "    margin=dict(\n",
    "        autoexpand=False,\n",
    "        l=100,\n",
    "        r=20,\n",
    "        t=110,\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    x=0.75,\n",
    "    y=1.3,\n",
    "),\n",
    "    barmode='relative', xaxis_tickangle=-45)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='The Most Affected City in Hokkaido',\n",
    "\n",
    "    xaxis_tickfont_size=10,\n",
    "    yaxis=dict(\n",
    "        title='Human Mobility Inflow Changes(%)',\n",
    "        color='rgb(37,37,37)',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=10,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis on trips change from outside hokkaido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hkk_19 = df_drop_19[df_drop_19['Origin Prefecture'] == '北海道']\n",
    "df_nothkk_19 = df_drop_19[df_drop_19['Origin Prefecture'] != '北海道']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hkk_19_date = df_hkk_19.groupby('date')['Ex Volume'].sum(\n",
    ").reset_index().rename(columns={'Ex Volume': 'vol_19_hkk'})\n",
    "df_nothkk_19_date = df_nothkk_19.groupby('date')['Ex Volume'].sum(\n",
    ").reset_index().rename(columns={'Ex Volume': 'vol_19_nothkk'})\n",
    "df_hkk_20_date = df_hkk_20.groupby('date')['Ex Volume'].sum(\n",
    ").reset_index().rename(columns={'Ex Volume': 'vol_20_hkk'})\n",
    "df_nothkk_20_date = df_nothkk_20.groupby('date')['Ex Volume'].sum(\n",
    ").reset_index().rename(columns={'Ex Volume': 'vol_20_nothkk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_19_date = pd.merge(df_hkk_19_date, df_nothkk_19_date, on='date')\n",
    "merge_20_date = pd.merge(df_hkk_20_date, df_nothkk_20_date, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_date = pd.merge(merge_19_date, merge_20_date, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data_x = merge_date.values.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-day average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_temp_1 = pd.DataFrame(merge_date.iloc[0]).T\n",
    "array_temp_2 = pd.DataFrame(merge_date.iloc[-1]).T\n",
    "merge_date = merge_date.append([array_temp_1]*3)\n",
    "merge_date = merge_date.append([array_temp_2]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_temp = merge_date.sort_values(\n",
    "    'date', ascending=True).iloc[:, 1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_data_y = data_temp.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = array_data_y[0].tolist()\n",
    "N = 7\n",
    "cumsum_1, moving_aves_1 = [0], []\n",
    "\n",
    "for i, x in enumerate(list_1, 1):\n",
    "\n",
    "    cumsum_1.append(cumsum_1[i-1] + x)\n",
    "    if i >= N:\n",
    "        moving_ave_1 = (cumsum_1[i] - cumsum_1[i-N])/N\n",
    "\n",
    "        moving_aves_1.append(moving_ave_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2 = array_data_y[1].tolist()\n",
    "N = 7\n",
    "cumsum_2, moving_aves_2 = [0], []\n",
    "\n",
    "for i, x in enumerate(list_2, 1):\n",
    "\n",
    "    cumsum_2.append(cumsum_2[i-1] + x)\n",
    "    if i >= N:\n",
    "        moving_ave_2 = (cumsum_2[i] - cumsum_2[i-N])/N\n",
    "\n",
    "        moving_aves_2.append(moving_ave_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_3 = array_data_y[2].tolist()\n",
    "N = 7\n",
    "cumsum_3, moving_aves_3 = [0], []\n",
    "\n",
    "for i, x in enumerate(list_3, 1):\n",
    "\n",
    "    cumsum_3.append(cumsum_3[i-1] + x)\n",
    "    if i >= N:\n",
    "        moving_ave_3 = (cumsum_3[i] - cumsum_3[i-N])/N\n",
    "\n",
    "        moving_aves_3.append(moving_ave_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_4 = array_data_y[3].tolist()\n",
    "N = 7\n",
    "cumsum_4, moving_aves_4 = [0], []\n",
    "\n",
    "for i, x in enumerate(list_4, 1):\n",
    "\n",
    "    cumsum_4.append(cumsum_4[i-1] + x)\n",
    "    if i >= N:\n",
    "        moving_ave_4 = (cumsum_4[i] - cumsum_4[i-N])/N\n",
    "\n",
    "        moving_aves_4.append(moving_ave_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Human Mobility Inflow Changes on Time Series'\n",
    "labels = ['2019', '2020']\n",
    "colors = ['#bebec0', '#008cc3']\n",
    "\n",
    "x_data = np.vstack((array_data_x,)*2)\n",
    "y_data = np.array([moving_aves_3, moving_aves_4])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i in range(0, 2):\n",
    "    fig.add_trace(go.Scatter(x=x_data[i], y=y_data[i], mode='lines',\n",
    "                             name=labels[i],\n",
    "                             line=dict(color=colors[i], width=2),\n",
    "                             connectgaps=True,\n",
    "                             ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[x_data[0][-1], x_data[1][-1]],\n",
    "        y=[y_data[0][-1], y_data[1][-1]],\n",
    "        mode='markers',\n",
    "        marker=dict(color=['#bebec0', '#008cc3', '#bebec0', '#008cc3'], size=6)\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=[x_data[1][27], x_data[1][27]], y=[0, 32746],\n",
    "                             mode='lines',\n",
    "                             name='event date',\n",
    "                             line=dict(color='#e16428',\n",
    "                                       width=1,\n",
    "                                       dash='dot')))\n",
    "    fig.add_trace(go.Scatter(x=[x_data[1][46], x_data[1][46]], y=[0, 32746],\n",
    "                             mode='lines',\n",
    "                             name='event date',\n",
    "                             line=dict(color='#e16428',\n",
    "                                       width=1,\n",
    "                                       dash='dot')))\n",
    "    fig.add_trace(go.Scatter(x=[x_data[1][73], x_data[1][73]], y=[0, 32746],\n",
    "                             mode='lines',\n",
    "                             name='event date',\n",
    "                             line=dict(color='#e16428',\n",
    "                                       width=1,\n",
    "                                       dash='dot')))\n",
    "    fig.add_trace(go.Scatter(x=[x_data[1][121], x_data[1][121]], y=[0, 32746],\n",
    "                             mode='lines',\n",
    "                             name='event date',\n",
    "                             line=dict(color='#e16428',\n",
    "                                       width=1,\n",
    "                                       dash='dot')))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            showgrid=False,\n",
    "            showticklabels=True,\n",
    "            linecolor='rgb(204, 204, 204)',\n",
    "            linewidth=2,\n",
    "            ticks='outside',\n",
    "            tickfont=dict(\n",
    "                family='Arial', size=12,\n",
    "                color='rgb(82, 82, 82)',\n",
    "            ),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            showline=True,\n",
    "            showticklabels=False,\n",
    "        ),\n",
    "        autosize=False,\n",
    "        margin=dict(\n",
    "            autoexpand=False,\n",
    "            l=100,\n",
    "            r=20,\n",
    "            t=110,\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    for y_trace, y_trace, label, color in zip(y_data, y_data, labels, colors):\n",
    "\n",
    "        annotations.append(dict(xref='paper', x=0.95, y=y_data[0][-1],\n",
    "                                xanchor='left', yanchor='middle',\n",
    "                                text=labels[0],\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=14,\n",
    "                                          color=colors[0]),\n",
    "                                showarrow=False))\n",
    "        annotations.append(dict(xref='paper', x=0.95, y=y_data[1][-1],\n",
    "                                xanchor='left', yanchor='middle',\n",
    "                                text=labels[1],\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=14,\n",
    "                                          color=colors[1]),\n",
    "                                showarrow=False))\n",
    "\n",
    "        annotations.append(dict(x=x_data[1][27], y=36000,\n",
    "                                xanchor='right', yanchor='top',\n",
    "                                text='lockdown was <br> declared',\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=12,\n",
    "                                          color='#e16428'),\n",
    "                                showarrow=False))\n",
    "        annotations.append(dict(x=x_data[1][121], y=39000,\n",
    "                                xanchor='left', yanchor='top',\n",
    "                                text='second time<br>lockdown was lifted',\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=12,\n",
    "                                          color='#e16428'),\n",
    "                                showarrow=False))\n",
    "        annotations.append(dict(x=x_data[1][73], y=36000,\n",
    "                                xanchor='left', yanchor='top',\n",
    "                                text='second time lockdown',\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=12,\n",
    "                                          color='#e16428'),\n",
    "                                showarrow=False))\n",
    "        annotations.append(dict(x=x_data[1][46], y=36000,\n",
    "                                xanchor='center', yanchor='top',\n",
    "                                text='lockdown was lift',\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=12,\n",
    "                                          color='#e16428'),\n",
    "                                showarrow=False))\n",
    "\n",
    "        annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.1,\n",
    "                                xanchor='left', yanchor='bottom',\n",
    "                                text='Human Mobility Inflow Changes on Time Series',\n",
    "                                font=dict(family='Arial',\n",
    "                                          size=16,\n",
    "                                          color='rgb(37,37,37)'),\n",
    "                                showarrow=False))\n",
    "\n",
    "fig.update_layout(annotations=annotations, xaxis_tickangle=-45)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
